{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-15T13:25:18.277629Z",
     "iopub.status.busy": "2021-10-15T13:25:18.277278Z",
     "iopub.status.idle": "2021-10-15T13:25:25.601296Z",
     "shell.execute_reply": "2021-10-15T13:25:25.600550Z",
     "shell.execute_reply.started": "2021-10-15T13:25:18.277539Z"
    },
    "id": "e394334d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection  import train_test_split,cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder,LabelEncoder\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "from transformers import BertTokenizer\n",
    "from transformers import TFAutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-15T13:25:25.603156Z",
     "iopub.status.busy": "2021-10-15T13:25:25.602892Z",
     "iopub.status.idle": "2021-10-15T13:25:34.227253Z",
     "shell.execute_reply": "2021-10-15T13:25:34.226306Z",
     "shell.execute_reply.started": "2021-10-15T13:25:25.603119Z"
    },
    "id": "-0sE31p_ElBG",
    "outputId": "a6a6a7df-4d55-4f17-fd29-aa06a283efa1"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-15T13:25:34.229048Z",
     "iopub.status.busy": "2021-10-15T13:25:34.228758Z",
     "iopub.status.idle": "2021-10-15T13:25:34.619184Z",
     "shell.execute_reply": "2021-10-15T13:25:34.618398Z",
     "shell.execute_reply.started": "2021-10-15T13:25:34.229010Z"
    },
    "id": "a3018fee"
   },
   "outputs": [],
   "source": [
    "sentiment = pd.read_csv('full_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-15T13:25:34.621680Z",
     "iopub.status.busy": "2021-10-15T13:25:34.621371Z",
     "iopub.status.idle": "2021-10-15T13:25:34.649569Z",
     "shell.execute_reply": "2021-10-15T13:25:34.648097Z",
     "shell.execute_reply.started": "2021-10-15T13:25:34.621641Z"
    },
    "id": "fa45e6da",
    "outputId": "692df6ff-1676-431d-8e08-cb9557efa413"
   },
   "outputs": [],
   "source": [
    "sentiment['Labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-15T13:25:34.651743Z",
     "iopub.status.busy": "2021-10-15T13:25:34.650901Z",
     "iopub.status.idle": "2021-10-15T13:25:34.660273Z",
     "shell.execute_reply": "2021-10-15T13:25:34.659277Z",
     "shell.execute_reply.started": "2021-10-15T13:25:34.651698Z"
    },
    "id": "ec6b853f"
   },
   "outputs": [],
   "source": [
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-15T13:25:34.662580Z",
     "iopub.status.busy": "2021-10-15T13:25:34.661963Z",
     "iopub.status.idle": "2021-10-15T13:25:58.700042Z",
     "shell.execute_reply": "2021-10-15T13:25:58.699311Z",
     "shell.execute_reply.started": "2021-10-15T13:25:34.662540Z"
    },
    "id": "7f9b9d2f",
    "outputId": "33fa072d-feea-4af7-b5f5-ff4ad722d8ee"
   },
   "outputs": [],
   "source": [
    "stopwords= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\"])\n",
    "\n",
    "def preprocess(data):\n",
    "    preprocessed_reviews = []\n",
    "    for sentance in tqdm(data):\n",
    "        sentance = re.sub(r\"http\\S+\", \"\", sentance)\n",
    "        sentance = BeautifulSoup(sentance, 'lxml').get_text()\n",
    "        sentance = decontracted(sentance)\n",
    "        sentance = re.sub(\"\\S*\\d\\S*\", \"\", sentance).strip()\n",
    "        sentance = re.sub('[^A-Za-z]+', ' ', sentance)\n",
    "        sentance = ' '.join(e.lower() for e in sentance.split() if e.lower() not in stopwords)\n",
    "        preprocessed_reviews.append(sentance.strip())\n",
    "    return preprocessed_reviews\n",
    "\n",
    "    \n",
    "sentiment_text = preprocess(sentiment['Text'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cb1e248"
   },
   "source": [
    "# SENTIMENT DATASET TOKENIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-15T13:31:40.470253Z",
     "iopub.status.busy": "2021-10-15T13:31:40.469657Z",
     "iopub.status.idle": "2021-10-15T13:31:40.475331Z",
     "shell.execute_reply": "2021-10-15T13:31:40.474176Z",
     "shell.execute_reply.started": "2021-10-15T13:31:40.470211Z"
    },
    "id": "15117d8f"
   },
   "outputs": [],
   "source": [
    "X=sentiment_text\n",
    "y=sentiment['Labels'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-15T13:31:40.650526Z",
     "iopub.status.busy": "2021-10-15T13:31:40.650291Z",
     "iopub.status.idle": "2021-10-15T13:31:40.678802Z",
     "shell.execute_reply": "2021-10-15T13:31:40.677852Z",
     "shell.execute_reply.started": "2021-10-15T13:31:40.650498Z"
    },
    "id": "ck45V8RiAwnw"
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-15T13:31:40.802881Z",
     "iopub.status.busy": "2021-10-15T13:31:40.802229Z",
     "iopub.status.idle": "2021-10-15T13:31:40.845601Z",
     "shell.execute_reply": "2021-10-15T13:31:40.844898Z",
     "shell.execute_reply.started": "2021-10-15T13:31:40.802838Z"
    },
    "id": "935b8b26"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-15T13:31:40.974913Z",
     "iopub.status.busy": "2021-10-15T13:31:40.974695Z",
     "iopub.status.idle": "2021-10-15T13:31:41.045937Z",
     "shell.execute_reply": "2021-10-15T13:31:41.045257Z",
     "shell.execute_reply.started": "2021-10-15T13:31:40.974888Z"
    },
    "id": "mKmG8OCu__Gi",
    "outputId": "f08b2114-4a47-4e20-c0a2-b0b3c796f5a6"
   },
   "outputs": [],
   "source": [
    "sentiment['Text'].apply(lambda x: len(str(x))).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-15T13:31:41.362508Z",
     "iopub.status.busy": "2021-10-15T13:31:41.362249Z",
     "iopub.status.idle": "2021-10-15T13:31:41.366745Z",
     "shell.execute_reply": "2021-10-15T13:31:41.365773Z",
     "shell.execute_reply.started": "2021-10-15T13:31:41.362476Z"
    },
    "id": "1lyfzN3DC1cl"
   },
   "outputs": [],
   "source": [
    "seq_len = 512\n",
    "batch_size = 32\n",
    "num_samples = len(X_train)\n",
    "model_name = 'distilbert-base-uncased-finetuned-sst-2-english'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-15T13:31:41.827211Z",
     "iopub.status.busy": "2021-10-15T13:31:41.826954Z",
     "iopub.status.idle": "2021-10-15T13:32:03.285236Z",
     "shell.execute_reply": "2021-10-15T13:32:03.284420Z",
     "shell.execute_reply.started": "2021-10-15T13:31:41.827182Z"
    },
    "id": "epBR9zT0C1VJ",
    "outputId": "62013921-ff90-43cf-be97-642799a853ff"
   },
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "train_tokens = tokenizer(X_train, max_length=seq_len, \n",
    "                         truncation=True, padding='max_length', \n",
    "                         add_special_tokens=True, return_tensors='np')\n",
    "\n",
    "# y_train = ytrain['target'].values\n",
    "labels = np.zeros((num_samples, y_train.max() + 1))\n",
    "labels[np.arange(num_samples), y_train] = 1\n",
    "# labels = y_train\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((train_tokens['input_ids'], train_tokens['attention_mask'], labels))\n",
    "\n",
    "def map_func(input_ids, masks, labels):\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': masks\n",
    "    }, labels\n",
    "\n",
    "dataset = dataset.map(map_func)\n",
    "dataset = dataset.shuffle(10000).batch(batch_size=batch_size, drop_remainder=True)\n",
    "\n",
    "split = 0.9\n",
    "size = int((train_tokens['input_ids'].shape[0] // batch_size) * split)\n",
    "\n",
    "train_ds = dataset.take(size)\n",
    "val_ds = dataset.skip(size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-15T13:32:03.287161Z",
     "iopub.status.busy": "2021-10-15T13:32:03.286901Z",
     "iopub.status.idle": "2021-10-15T15:02:48.092243Z",
     "shell.execute_reply": "2021-10-15T15:02:48.091377Z",
     "shell.execute_reply.started": "2021-10-15T13:32:03.287125Z"
    },
    "id": "-GRpEMfjnTvI",
    "outputId": "69194347-f0b0-49c5-f448-6152c7ade86c"
   },
   "outputs": [],
   "source": [
    "model = TFAutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Two inputs\n",
    "input_ids = tf.keras.layers.Input(shape=(seq_len,), name='input_ids', dtype='int32')\n",
    "mask = tf.keras.layers.Input(shape=(seq_len,), name='attention_mask', dtype='int32')\n",
    "\n",
    "# Transformer\n",
    "# embeddings = model.bert(input_ids, attention_mask=mask)[1]\n",
    "embeddings = model(input_ids, attention_mask=mask)[0]\n",
    "embeddings = embeddings[:, 0, :]\n",
    "# Classifier head\n",
    "x = tf.keras.layers.Dense(512, activation='relu')(embeddings)\n",
    "# x = tf.keras.layers.Dropout(0.1)(x)\n",
    "y = tf.keras.layers.Dense(len(set(y)), activation='softmax', name='outputs')(x)\n",
    "\n",
    "bert_model = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
    "\n",
    "# freeze bert layers\n",
    "# bert_model.layers[2].trainable = False\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lr=1e-5)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "acc = tf.keras.metrics.BinaryAccuracy()\n",
    "\n",
    "bert_model.compile(optimizer=optimizer, loss=loss, metrics=[acc])\n",
    "\n",
    "history = bert_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=5,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-15T15:03:02.170755Z",
     "iopub.status.busy": "2021-10-15T15:03:02.170496Z",
     "iopub.status.idle": "2021-10-15T15:03:02.178882Z",
     "shell.execute_reply": "2021-10-15T15:03:02.177071Z",
     "shell.execute_reply.started": "2021-10-15T15:03:02.170725Z"
    },
    "id": "jJWcOTMfn4b1"
   },
   "outputs": [],
   "source": [
    "def plot_learning_evolution(r):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(r.history['loss'], label='Loss')\n",
    "    plt.plot(r.history['val_loss'], label='val_Loss')\n",
    "    plt.title('Loss evolution during trainig')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(r.history['binary_accuracy'], label='binary_accuracy')\n",
    "    plt.plot(r.history['val_binary_accuracy'], label='val_binary_accuracy')\n",
    "    plt.title('Accuracy score evolution during trainig')\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-15T15:03:07.043008Z",
     "iopub.status.busy": "2021-10-15T15:03:07.042187Z",
     "iopub.status.idle": "2021-10-15T15:03:07.083787Z",
     "shell.execute_reply": "2021-10-15T15:03:07.082657Z",
     "shell.execute_reply.started": "2021-10-15T15:03:07.042952Z"
    },
    "id": "JOsitp0uvTpY",
    "outputId": "96b4bdba-0cd7-4c30-975f-b2351b6bb209"
   },
   "outputs": [],
   "source": [
    "plot_learning_evolution(history)\n",
    "bert_model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DFbdtPdgvTlz"
   },
   "outputs": [],
   "source": [
    "def prep_data(text):\n",
    "    tokens = tokenizer(text, max_length=512, truncation=True, \n",
    "                       padding='max_length', \n",
    "                       add_special_tokens=True, \n",
    "                       return_tensors='tf')\n",
    "    return {'input_ids': tokens['input_ids'], \n",
    "            'attention_mask': tokens['attention_mask']}\n",
    "\n",
    "test['target'] = None\n",
    "\n",
    "for i, row in test.iterrows():\n",
    "    tokens = prep_data(row['text'])\n",
    "    probs = bert_model.predict(tokens)\n",
    "    pred = np.argmax(probs)\n",
    "    test.at[i, 'target'] = pred\n",
    "    \n",
    "test['target'] = test['target'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-15T15:07:54.621965Z",
     "iopub.status.busy": "2021-10-15T15:07:54.621206Z",
     "iopub.status.idle": "2021-10-15T15:07:54.627817Z",
     "shell.execute_reply": "2021-10-15T15:07:54.627040Z",
     "shell.execute_reply.started": "2021-10-15T15:07:54.621915Z"
    },
    "id": "64XfG2RnvTe6"
   },
   "outputs": [],
   "source": [
    "bert_model.save_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-15T15:08:14.292658Z",
     "iopub.status.busy": "2021-10-15T15:08:14.291836Z",
     "iopub.status.idle": "2021-10-15T15:08:14.713115Z",
     "shell.execute_reply": "2021-10-15T15:08:14.712302Z",
     "shell.execute_reply.started": "2021-10-15T15:08:14.292615Z"
    },
    "id": "kFcH0DDXvTb8"
   },
   "outputs": [],
   "source": [
    "bert_model.save_weights('weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nWLAH5PzvTS3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wLIceaEJvTPb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
